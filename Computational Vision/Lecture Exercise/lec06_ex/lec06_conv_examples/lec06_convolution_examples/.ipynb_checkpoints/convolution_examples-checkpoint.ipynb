{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 7 Demonstration of Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This explores some of the image processing - image filtering - operations in OpenCV.  A good reference is\n",
    "http://docs.opencv.org/3.1.0/d4/d13/tutorial_py_filtering.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pics( image_list, num_in_col=2, title_list=[]):\n",
    "    '''\n",
    "    Given a list of images, plot them in a grid using PyPlot\n",
    "    '''\n",
    "    if len(image_list) == 0: return\n",
    "    if len(image_list[0].shape) == 2:\n",
    "        plt.gray()\n",
    "    num_rows = m.ceil(len(image_list)/num_in_col)\n",
    "    if num_in_col > 2:\n",
    "        plt.figure(figsize=(12,12))\n",
    "    else:\n",
    "        plt.figure(figsize=(15,15))\n",
    "    for i in range(len(image_list)):\n",
    "        im = image_list[i]\n",
    "        print(num_rows, num_in_col, i+1)\n",
    "        plt.subplot(num_rows, num_in_col, i+1)\n",
    "        plt.imshow(im)\n",
    "        if i < len(title_list):\n",
    "            plt.title(title_list[i])\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Apply 5x5, 9x9 and 15x15 box filters.\n",
    "The OpenCV function boxFilter() is almost equivalent.\n",
    "'''\n",
    "im = cv2.imread('new_york_hop.jpg',cv2.IMREAD_GRAYSCALE )\n",
    "# im = cv2.resize(im, (im.shape[1]//4, im.shape[0]//4))\n",
    "print(im.shape)\n",
    "blur5 = cv2.blur(im,(5,5))\n",
    "blur9 = cv2.blur(im,(9,9))\n",
    "blur15 = cv2.blur(im,(45,45))\n",
    "im_list = [im,blur5,blur9,blur15]\n",
    "title_list = ['Original', '5x5', '9x9', '15x15']\n",
    "plot_pics(im_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.resize(im, (im.shape[1]//4, im.shape[0]//4))\n",
    "print(im.shape)\n",
    "blur5 = cv2.blur(im,(5,5))\n",
    "blur9 = cv2.blur(im,(9,9))\n",
    "blur15 = cv2.blur(im,(45,45))\n",
    "im_list = [im,blur5,blur9,blur15]\n",
    "title_list = ['Original', '5x5', '9x9', '15x15']\n",
    "plot_pics(im_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We can do the same thing with the color image.  Each channel is filtered separately,\n",
    "without our having to do anything explicitly!\n",
    "'''\n",
    "im = cv2.imread('Municipal_Building_-_New_York_City.jpg')\n",
    "print(im.shape)\n",
    "im = im[:,:,::-1]\n",
    "# im = np.transpose(im, axes=(1,0,2))\n",
    "im = np.rot90(im, axes=(0,1))\n",
    "blur5 = cv2.blur(im,(5,5))\n",
    "blur9 = cv2.blur(im,(9,9))\n",
    "blur15 = cv2.blur(im,(15,15))\n",
    "im_list = [im,blur5,blur9,blur15]\n",
    "title_list = ['Original', '5x5', '9x9', '15x15']\n",
    "plot_pics(im_list,2,title_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now let's try Gaussian smoothing.\n",
    "We specify the kernel as covering +/- 2 sigma pixels.\n",
    "'''\n",
    "im = cv2.imread('New-York-City---Manhattan---Central-Park---(Gentry).jpg')\n",
    "im = im[:,:,::-1]\n",
    "sigma = 1\n",
    "n = 5\n",
    "im_list = [ im ]\n",
    "title_list = [ 'Original' ]\n",
    "for i in range(n):\n",
    "    ksize = (4*sigma+1,4*sigma+1)\n",
    "    im_s = cv2.GaussianBlur(im, ksize, sigma)\n",
    "    im_list += [im_s]\n",
    "    title_list += [ 'sigma = ' + str(sigma) ]\n",
    "    sigma *= 2\n",
    "plot_pics(im_list,2,title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now we are going to compute the derivatives by forming two 2d kernels.\n",
    "We'll start by applying this to a toy example.\n",
    "'''\n",
    "toy_image = np.array( [ [ 0,  0,  0,  0,  0,  0,  0,  0 ],\n",
    "                        [ 0,  0,  0,  0,  0,  0,  0,  0 ],\n",
    "                        [ 0,  0, 99, 99, 99, 99,  0,  0 ],\n",
    "                        [ 0,  0, 99, 99, 99, 99,  0,  0 ],\n",
    "                        [ 0,  0, 99, 99, 99, 99,  0,  0 ],\n",
    "                        [ 0,  0, 99, 99, 99, 99,  0,  0 ],\n",
    "                        [ 0,  0, 99, 99, 99, 99,  0,  0 ],\n",
    "                        [ 0,  0,  0,  0,  0,  0,  0,  0 ],\n",
    "                        [ 0,  0,  0,  0,  0,  0,  0,  0 ] ], dtype = np.float32 )\n",
    "\n",
    "dx_kernel = np.array( [[-0.5, 0, 0.5]])\n",
    "print(\"X derivate kernel\")\n",
    "print(dx_kernel)\n",
    "im_dx = cv2.filter2D( toy_image, -1, dx_kernel)   # -1 means to use toy_image's pixel type\n",
    "print(\"\\nX derivative result\")\n",
    "print(im_dx)\n",
    "\n",
    "dy_kernel = np.array( [[-0.5], [0], [0.5]] )\n",
    "print(\"\\nY derivate kernel\")\n",
    "print(dy_kernel)\n",
    "im_dy = cv2.filter2D( toy_image, -1, dy_kernel)\n",
    "print(\"\\nY derivative result\")\n",
    "print(im_dy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now we can apply these operations to a \"real\" image.\n",
    "We'll start by converting to gray scale\n",
    "'''\n",
    "im_gray = cv2.imread(\"New-York-skyline_0.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "im_dx = cv2.filter2D( im_gray, cv2.CV_32F, dx_kernel)\n",
    "im_dy = cv2.filter2D( im_gray, cv2.CV_32F, dy_kernel)\n",
    "im_dx_abs = np.abs(2*im_dx).astype(np.uint8)\n",
    "im_dy_abs = np.abs(2*im_dy).astype(np.uint8)\n",
    "im_list = [im_gray, im_dx_abs, im_dy_abs]\n",
    "title_list = [ \"Gray scale\", \"x derivative magnitude\", \"y derivative magnitude\" ]\n",
    "\n",
    "plot_pics(im_list,2,title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here is a purely NumPy way to calculate derivatives.  This is \n",
    "more for illustrative purposes.  In practice, OpenCV functions\n",
    "should be used unless there is a specific reason not to do so.\n",
    "\n",
    "Notes:\n",
    "1. Boundary effects are handled by initializing to 0 on\n",
    "the outside of the image.\n",
    "2. Slicing is used to implicitly shift the images one pixel\n",
    "to the left and to the right so that x derivatives can be\n",
    "calculated with simple arithmetic operations.  The same is\n",
    "true for the y derivative.\n",
    "'''\n",
    "print(\"Toy image again:\")\n",
    "print(toy_image)\n",
    "im_dx = np.zeros_like(toy_image, dtype=np.float32)\n",
    "left_shift = toy_image[1:-1, :-2]\n",
    "right_shift = toy_image[1:-1, 2:]\n",
    "im_dx[1:-1, 1:-1] = 0.5*right_shift - 0.5*left_shift\n",
    "print(\"\\nX derivative result\")\n",
    "print(im_dx)\n",
    "\n",
    "im_dy = np.zeros_like(toy_image, dtype = np.float32)\n",
    "down_shift = toy_image[:-2, 1:-1]\n",
    "up_shift = toy_image[2:, 1:-1]\n",
    "im_dy[1:-1, 1:-1] = 0.5*up_shift - 0.5*down_shift\n",
    "print(\"\\nY derivative result\")\n",
    "print(im_dy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Finally, we compute the \"Sobel\" derivatives.  These have 3x3 kernels\n",
    "    -1 0 1      -1 -2 -1\n",
    "    -2 0 2  and  0  0  0\n",
    "    -1 0 1       1  2  1\n",
    "for the dx and dy derivatives, respectively.  This includes a bit of\n",
    "smoothing in the differentiation.\n",
    "'''\n",
    "print(\"Toy image again:\")\n",
    "print(toy_image)\n",
    "im_dx = cv2.Sobel( toy_image, -1, 1, 0)\n",
    "print(\"\\nX Sobel derivative result\")\n",
    "print(im_dx)\n",
    "im_dy = cv2.Sobel( toy_image, -1, 0, 1)\n",
    "print(\"\\nY Sobel derivative result\")\n",
    "print(im_dy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sobel on a real image\n",
    "'''\n",
    "im_dx = cv2.Sobel(im_gray, cv2.CV_32F, 1, 0)\n",
    "im_dy = cv2.Sobel(im_gray, cv2.CV_32F, 0, 1)\n",
    "im_dx_abs = np.abs(im_dx).astype(np.uint8)\n",
    "im_dy_abs = np.abs(im_dy).astype(np.uint8)\n",
    "im_list = [im_gray, im_dx_abs, im_dy_abs]\n",
    "title_list = [\"Gray scale\", \"Sobel x derivative magnitude\", \"Sobel y derivative magnitude\"]\n",
    "\n",
    "plot_pics(im_list,2,title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now we'll try some mathematical morphology.  First, a \"binarized\"\n",
    "image (a silhouette) of a hand.  What do you see?\n",
    "'''\n",
    "hand_img = cv2.imread('hand.png')\n",
    "plot_pics( [hand_img], 2, ['hand.png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "First let's try erosion:\n",
    "\n",
    "'''\n",
    "kernel3 = np.ones((3,3),np.uint8)\n",
    "eroded3 = cv2.erode(hand_img,kernel3,iterations = 1)\n",
    "kernel5 = np.ones((5,5),np.uint8)\n",
    "eroded5 = cv2.erode(hand_img,kernel5,iterations = 1)\n",
    "kernel25 = np.ones((25,25),np.uint8)\n",
    "eroded25 = cv2.erode(hand_img,kernel25,iterations = 1)\n",
    "plot_pics( [hand_img, eroded3, eroded5, eroded25], 2,\n",
    "           ['hand.png', 'Eroded 3x3', 'Eroded 5x5', 'Eroded 25x25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Next, let's try dilation:\n",
    "'''\n",
    "dilated3 = cv2.dilate(hand_img,kernel3,iterations = 1)\n",
    "dilated5 = cv2.dilate(hand_img,kernel5,iterations = 1)\n",
    "dilated25 = cv2.dilate(hand_img,kernel25,iterations = 1)\n",
    "plot_pics( [hand_img, dilated3, dilated5, dilated25], 2,\n",
    "           ['hand.png', 'Dilated 3x3', 'Dilated 5x5', 'Dilated 25x25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Opening next\n",
    "'''\n",
    "open3 = cv2.morphologyEx(hand_img, cv2.MORPH_OPEN, kernel3)\n",
    "open5 = cv2.morphologyEx(hand_img, cv2.MORPH_OPEN, kernel5)\n",
    "open25 = cv2.morphologyEx(hand_img, cv2.MORPH_OPEN, kernel25)\n",
    "plot_pics( [hand_img, open3, open5, open25], 2,\n",
    "           ['hand.png', 'Opened 3x3', 'Opened 5x5', 'Opened 25x25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Closing next\n",
    "'''\n",
    "close3 = cv2.morphologyEx(hand_img, cv2.MORPH_CLOSE, kernel3)\n",
    "close5 = cv2.morphologyEx(hand_img, cv2.MORPH_CLOSE, kernel5)\n",
    "close25 = cv2.morphologyEx(hand_img, cv2.MORPH_CLOSE, kernel25)\n",
    "plot_pics( [hand_img, close3, close5, close25], 2,\n",
    "           ['hand.png', 'Opened 3x3', 'Opened 5x5', 'Opened 25x25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now for a demo of median filtering.  First with a picture of a zebra corrupted\n",
    "by salt-and-pepper noise.\n",
    "'''\n",
    "zebra_img = cv2.imread('ZebraWithAttachedShadow_noisy_Salt_and_Pepper.jpg',\n",
    "                        cv2.IMREAD_GRAYSCALE)\n",
    "zebra_median3 = cv2.medianBlur(zebra_img, 3)\n",
    "zebra_median5 = cv2.medianBlur(zebra_img, 5)\n",
    "zebra_median7 = cv2.medianBlur(zebra_img, 7)\n",
    "plot_pics( [zebra_img, zebra_median3, zebra_median5, zebra_median7], 2,\n",
    "           ['Zebra Image', 'Median 3x3', 'Median 5x5', 'Median 7x7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Second, with a much tougher case of a corrupted picture of a ship.\n",
    "The result is cartoon-like.\n",
    "'''\n",
    "ship_img = cv2.imread('ship-salt-and-pepper.jpg',\n",
    "                       cv2.IMREAD_GRAYSCALE)\n",
    "ship_median3 = cv2.medianBlur(ship_img, 3)\n",
    "ship_median5 = cv2.medianBlur(ship_img, 5)\n",
    "ship_median7 = cv2.medianBlur(ship_img, 7)\n",
    "plot_pics( [ship_img, ship_median3, ship_median5, ship_median7], 2,\n",
    "           ['Ship Image', 'Median 3x3', 'Median 5x5', 'Median 7x7'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
